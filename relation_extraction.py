import pandas as pd
import re
from itertools import combinations
from neo4j import GraphDatabase
from tqdm import tqdm
import json
from google.genai import Client, types
from typing import Optional, Dict, List
import time
import os
import asyncio


# Track request count for each API key
current_api_index = 0  
request_count = 0  
lock = asyncio.Lock()

API_KEYS = os.getenv("GEMINI_API_KEYS", "").split(",")

async def get_api_key():
    """Returns an API key, switching every 3 requests for faster rotation"""
    global current_api_index, request_count
    
    async with lock:
        api_key = API_KEYS[current_api_index]
        request_count += 1  
        
        if request_count >= 3:  # Reduced from 5 to 3 for faster rotation
            current_api_index = (current_api_index + 1) % len(API_KEYS)
            request_count = 0  
    
    return api_key

# C·∫•u h√¨nh Gemini API
# GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
# client = Client(api_key=GEMINI_API_KEY)

# Load relation patterns
with open("relation_vocab.json", "r", encoding="utf-8") as f:
    RELATION_PATTERNS = json.load(f)

# T·∫°o description cho t·ª´ng lo·∫°i relation
RELATION_DESCRIPTIONS = {
    "ORG_LOCATION": "Quan h·ªá v·ªÅ v·ªã tr√≠ ƒë·ªãa l√Ω, n∆°i ƒë·∫∑t tr·ª• s·ªü, ho·∫°t ƒë·ªông c·ªßa t·ªï ch·ª©c",
    "ADMINISTRATIVE_GOVERNANCE": "Quan h·ªá qu·∫£n l√Ω, ch·ªâ ƒë·∫°o, ƒëi·ªÅu h√†nh, ph√™ duy·ªát c·ªßa c∆° quan nh√† n∆∞·ªõc",
    "ACTION_INTERACTION": "C√°c h√†nh ƒë·ªông, t∆∞∆°ng t√°c tr·ª±c ti·∫øp gi·ªØa c√°c th·ª±c th·ªÉ",
    "CAUSE_EFFECT": "Quan h·ªá nguy√™n nh√¢n - k·∫øt qu·∫£, ·∫£nh h∆∞·ªüng",
    "TEMPORAL": "Quan h·ªá v·ªÅ th·ªùi gian, m·ªëc th·ªùi gian, kho·∫£ng th·ªùi gian",
    "SPATIAL": "Quan h·ªá kh√¥ng gian, ph∆∞∆°ng h∆∞·ªõng, v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi",
    "ROLE_FUNCTION": "Vai tr√≤, ch·ª©c v·ª•, ch·ª©c nƒÉng c·ªßa ng∆∞·ªùi ho·∫∑c t·ªï ch·ª©c",
    "EVENT_PARTICIPATION": "Tham gia, t·ªï ch·ª©c, th·ª±c hi·ªán s·ª± ki·ªán",
    "KNOWLEDGE_ACADEMIC": "Quan h·ªá h·ªçc thu·∫≠t, nghi√™n c·ª©u, gi√°o d·ª•c",
    "COMPARISON_CONTRAST": "So s√°nh, ƒë·ªëi chi·∫øu gi·ªØa c√°c th·ª±c th·ªÉ",
    "PURPOSE_INTENT": "M·ª•c ƒë√≠ch, √Ω ƒë·ªãnh c·ªßa h√†nh ƒë·ªông",
    "METHOD_MANNER": "Ph∆∞∆°ng th·ª©c, c√°ch th·ª©c th·ª±c hi·ªán",
    "PHYSICAL_TECHNICAL": "Quan h·ªá v·∫≠t l√Ω, k·ªπ thu·∫≠t, c·∫•u tr√∫c",
    "COMMERCIAL_ECONOMIC": "Quan h·ªá th∆∞∆°ng m·∫°i, kinh t·∫ø, mua b√°n",
    "LEGAL": "Quan h·ªá ph√°p l√Ω, lu·∫≠t ph√°p, vi ph·∫°m",
    "SOCIAL_PERSONAL": "Quan h·ªá x√£ h·ªôi, gia ƒë√¨nh, c√° nh√¢n",
    "POSSESSION_ATTRIBUTE": "S·ªü h·ªØu, thu·ªôc t√≠nh, ƒë·∫∑c ƒëi·ªÉm",
    "MEMBERSHIP": "Th√†nh vi√™n, thu·ªôc v·ªÅ m·ªôt nh√≥m/t·ªï ch·ª©c",
    "REGULATION_COMPLIANCE": "Tu√¢n th·ªß, quy ƒë·ªãnh, quy chu·∫©n"
}

# Cache ƒë·ªÉ tr√°nh g·ªçi API nhi·ªÅu l·∫ßn cho c√πng c√¢u
relation_cache: Dict[str, Optional[str]] = {}

def create_relation_prompt(sentence: str, entities: List[str]) -> str:
    """T·∫°o prompt cho LLM ƒë·ªÉ ph√¢n lo·∫°i relation"""
    
    # T·∫°o danh s√°ch c√°c relation types v·ªõi m√¥ t·∫£
    relation_list = "\n".join([
        f"- {rel_type}: {desc}" 
        for rel_type, desc in RELATION_DESCRIPTIONS.items()
    ])
    
    entities_str = ", ".join(f'"{e}"' for e in entities)
    
    prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch quan h·ªá gi·ªØa c√°c th·ª±c th·ªÉ trong vƒÉn b·∫£n ti·∫øng Vi·ªát.

    NHI·ªÜM V·ª§: X√°c ƒë·ªãnh lo·∫°i quan h·ªá ch√≠nh gi·ªØa c√°c th·ª±c th·ªÉ trong c√¢u sau.

    C√ÇU C·∫¶N PH√ÇN T√çCH:
    "{sentence}"

    C√ÅC TH·ª∞C TH·ªÇ TRONG C√ÇU:
    {entities_str}

    DANH S√ÅCH C√ÅC LO·∫†I QUAN H·ªÜ H·ª¢P L·ªÜ:
    {relation_list}

    QUY T·∫ÆC:
    1. Ch·ªâ ƒë∆∞·ª£c ch·ªçn M·ªòT lo·∫°i quan h·ªá ph√π h·ª£p nh·∫•t t·ª´ danh s√°ch tr√™n
    2. KH√îNG ƒë∆∞·ª£c t·∫°o ra lo·∫°i quan h·ªá m·ªõi ngo√†i danh s√°ch
    3. N·∫øu kh√¥ng c√≥ quan h·ªá n√†o ph√π h·ª£p, tr·∫£ v·ªÅ "NONE"
    4. Ch·ªâ tr·∫£ v·ªÅ T√äN LO·∫†I QUAN H·ªÜ (v√≠ d·ª•: ORG_LOCATION), kh√¥ng gi·∫£i th√≠ch th√™m

    TR·∫¢ L·ªúI (ch·ªâ t√™n lo·∫°i quan h·ªá):"""
    
    return prompt

async def detect_relation_with_llm(sentence: str, entities: List[str], max_retries: int = 3) -> Optional[str]:
    """
    S·ª≠ d·ª•ng Gemini ƒë·ªÉ detect relation v·ªõi ng·ªØ nghƒ©a
    
    Args:
        sentence: C√¢u c·∫ßn ph√¢n t√≠ch
        entities: Danh s√°ch entities trong c√¢u
        max_retries: S·ªë l·∫ßn th·ª≠ l·∫°i n·∫øu g·∫∑p l·ªói
    
    Returns:
        T√™n relation type ho·∫∑c None
    """
    # Ki·ªÉm tra cache
    cache_key = sentence.strip().lower()
    if cache_key in relation_cache:
        return relation_cache[cache_key]
    
    api_key = await get_api_key()
    client = Client(api_key=api_key)

    # T·∫°o prompt
    prompt = create_relation_prompt(sentence, entities)
    
    # G·ªçi LLM v·ªõi retry logic
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.UserContent(
                        parts=[types.Part.from_text(text=prompt)]
                    )
                ],
                config=types.GenerateContentConfig(temperature=0.1, max_output_tokens=50)
            )
            
            # L·∫•y k·∫øt qu·∫£ v√† chu·∫©n h√≥a
            print(response.text)
            if response.text is not None:
                result = response.text.strip().upper()
            else:
                result = "NONE"
            
            # Ki·ªÉm tra result c√≥ h·ª£p l·ªá kh√¥ng
            if result == "NONE":
                relation_cache[cache_key] = None
                return None
            
            if result in RELATION_DESCRIPTIONS:
                relation_cache[cache_key] = result
                return result
            
            # N·∫øu LLM tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng format, th·ª≠ parse
            for rel_type in RELATION_DESCRIPTIONS.keys():
                if rel_type in result:
                    relation_cache[cache_key] = rel_type
                    return rel_type
            
            # N·∫øu kh√¥ng match ƒë∆∞·ª£c, tr·∫£ v·ªÅ None
            relation_cache[cache_key] = None
            return None
            
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è  L·ªói khi g·ªçi API (th·ª≠ l·∫°i {attempt + 1}/{max_retries}): {e}")
                time.sleep(2 ** attempt)  # Exponential backoff
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ g·ªçi API sau {max_retries} l·∫ßn th·ª≠: {e}")
                return None
    
    return None

async def detect_relation_hybrid(sentence: str, entities: List[str]) -> Optional[str]:
    """
    Ph∆∞∆°ng ph√°p hybrid: Th·ª≠ exact match tr∆∞·ªõc, n·∫øu kh√¥ng c√≥ th√¨ d√πng LLM
    Gi√∫p ti·∫øt ki·ªám API calls v√† tƒÉng t·ªëc ƒë·ªô
    """
    # Th·ª≠ exact match tr∆∞·ªõc (nhanh v√† mi·ªÖn ph√≠)
    for rel, patterns in RELATION_PATTERNS.items():
        for p in patterns:
            if re.search(p, sentence.lower()):
                return rel
    
    # N·∫øu kh√¥ng match ƒë∆∞·ª£c, d√πng LLM
    return await detect_relation_with_llm(sentence, entities)

# Ki·ªÉm tra entity h·ª£p l·ªá
def is_valid_entity(text):
    """
    Entity h·ª£p l·ªá ph·∫£i ch·ª©a √≠t nh·∫•t 1 k√Ω t·ª± ch·ªØ c√°i ho·∫∑c ch·ªØ s·ªë.
    Lo·∫°i b·ªè c√°c entity ch·ªâ ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát.
    """
    if not text or not text.strip():
        return False
    return bool(re.search(r'\w', text))

# Chu·∫©n h√≥a relation type cho Neo4j
def normalize_relation_type(rel_type):
    """
    Chu·∫©n h√≥a relation type ƒë·ªÉ h·ª£p l·ªá v·ªõi Neo4j:
    - Kh√¥ng ƒë∆∞·ª£c b·∫Øt ƒë·∫ßu b·∫±ng s·ªë
    - Ch·ªâ ch·ª©a ch·ªØ c√°i, s·ªë, underscore
    - Vi·∫øt hoa to√†n b·ªô
    """
    rel_type = str(rel_type).strip()
    
    if rel_type and rel_type[0].isdigit():
        rel_type = "REL_" + rel_type
    
    rel_type = re.sub(r'[^a-zA-Z0-9_]', '_', rel_type)
    rel_type = rel_type.upper()
    
    return rel_type if rel_type else "UNKNOWN_RELATION"

# G·ª≠i batch quan h·ªá v√†o Neo4j
def write_relation_batch(tx, rows, progress_bar=None):
    """G·ª≠i batch quan h·ªá v√†o Neo4j v·ªõi progress bar"""
    relation_groups = {}
    
    for row in rows:
        rel_type = normalize_relation_type(row['relation'])
        if rel_type not in relation_groups:
            relation_groups[rel_type] = []
        relation_groups[rel_type].append(row)
    
    for rel_type, rel_rows in relation_groups.items():
        query = f"""
        UNWIND $rows AS row
        MATCH (a:Entity {{name: row.e1}})
        MATCH (b:Entity {{name: row.e2}})
        MERGE (a)-[r:{rel_type}]->(b)
        ON CREATE SET r.example = row.sentence
        """
        tx.run(query, rows=rel_rows)
    
    if progress_bar:
        progress_bar.update(len(rows))

# ============================================
# MAIN PROCESSING
# ============================================

async def main():
    print("B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t quan h·ªá t·ª´ extracted_entities.csv...")

    # ƒê·ªçc file CSV
    df = pd.read_csv("extracted_entities.csv")

    # L·ªçc theo date t·ª´ th√°ng 11 tr·ªü ƒëi
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df[df["date"].dt.month >= 11]

    print(f"S·ªë d√≤ng sau khi l·ªçc: {len(df)}")

    # Tr√≠ch xu·∫•t quan h·ªá
    rows = []
    grouped = df.groupby("sentence")

    print("ƒêang tr√≠ch xu·∫•t quan h·ªá v·ªõi LLM...")
    print("üí° S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p hybrid: exact match + LLM")

    for sent, group in tqdm(grouped, desc="Processing sentences"):
        entities = group["entity"].unique().tolist()
        
        if len(entities) < 2:
            continue
        
        # S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p hybrid
        rel = await detect_relation_hybrid(sent, entities)
        
        if not rel:
            continue
        
        for e1, e2 in combinations(entities, 2):
            # Ki·ªÉm tra entity h·ª£p l·ªá
            if not is_valid_entity(e1) or not is_valid_entity(e2):
                continue
            
            rows.append({
                "e1": e1.strip(),
                "e2": e2.strip(),
                "relation": rel.strip(),
                "sentence": sent.strip()
            })

    # T·∫°o DataFrame v√† l∆∞u file
    rel_df = pd.DataFrame(rows)
    rel_df.to_csv("relations.csv", index=False)
    print(f"‚úì ƒê√£ t·∫°o file relations.csv v·ªõi {len(rel_df)} quan h·ªá.")
    print(f"üìä Cache hits: {len(relation_cache)} c√¢u ƒë√£ ƒë∆∞·ª£c cache")

    # ============================================
    # G·ª¨I QUAN H·ªÜ V√ÄO NEO4J
    # ============================================

    try:
        # K·∫øt n·ªëi Neo4j
        uri = os.getenv("NEO4J_URI")
        user = os.getenv("NEO4J_USER")
        password = os.getenv("NEO4J_PASSWORD")
        driver = GraphDatabase.driver(uri, auth=(user, password))

        chunk_size = 50_000
        batch_size = 10_000

        print("\nB·∫Øt ƒë·∫ßu g·ª≠i quan h·ªá v√†o Neo4j...")

        with driver.session() as session:
            chunk_reader = pd.read_csv("relations.csv", chunksize=chunk_size)
            
            for chunk_idx, chunk in enumerate(chunk_reader, start=1):
                print(f"\nƒêang x·ª≠ l√Ω chunk {chunk_idx} ({len(chunk)} d√≤ng)...")
                
                batch_rows = []
                for _, row in chunk.iterrows():
                    e1 = str(row.get("e1", "")).strip()
                    e2 = str(row.get("e2", "")).strip()
                    relation = str(row.get("relation", "")).strip()
                    sentence = str(row.get("sentence", "")).strip()
                    
                    if not e1 or not e2 or not relation:
                        continue
                    
                    batch_rows.append({
                        "e1": e1,
                        "e2": e2,
                        "relation": relation,
                        "sentence": sentence
                    })
                
                if not batch_rows:
                    print(f"Chunk {chunk_idx}: Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá")
                    continue
                
                print(f"G·ª≠i {len(batch_rows)} quan h·ªá v√†o Neo4j...")
                with tqdm(
                    total=len(batch_rows),
                    desc=f"Chunk {chunk_idx}",
                    unit="relations",
                    ncols=100
                ) as pbar:
                    for i in range(0, len(batch_rows), batch_size):
                        mini_batch = batch_rows[i:i + batch_size]
                        session.execute_write(write_relation_batch, mini_batch, pbar)
                
                print(f"‚úì Ho√†n t·∫•t chunk {chunk_idx}")
    except Exception as e:
        print(f"‚ùå L·ªói khi ghi v√†o Neo4j: {e}")
    finally:
        driver.close()
        
    print("\n‚úì Ho√†n t·∫•t t·∫•t c·∫£!")
    print(f"üìà T·ªïng s·ªë c√¢u ƒë√£ x·ª≠ l√Ω qua LLM: {len([v for v in relation_cache.values() if v is not None])}")


if __name__ == "__main__":
    asyncio.run(main())
